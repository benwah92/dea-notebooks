{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Assessment of dNBR Classification <img align=\"right\" src=\"../DEA reference notebooks/Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `NCI VDI` or a `Local` environment only.\n",
    "* **Products derived from previously processed data:** \n",
    "[s2a_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2a_ard_granule), \n",
    "[s2b_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2b_ard_granule),\n",
    "[planet_dove](https://planet.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "During the 2020 Black Summer Bushfires, the town of Tumbarumba, NSW was impacted by a fire event that occured on the 05 Jan 2020. This notebook is a supporting notebook to the `differenced normalised burn ratio` notebook. Having already produced the output dNBR GeoTIFF product, Planet Data (sourced under a Planet education and research license) was used to extract and classify points in accordance with the fire severity classes (unburt, low, moderate, high extreme). Producing accuracy assessments is critical to validating the results produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook is used to generate accuracy results for fire severity and fire extent. No connection is required to the NCI, as no connection to the datacube is required. Accuracy data (derived from Planet Dove imagery) has been provided as a shapefile and includes the dNBR value, the actual severity that was visually interpretted and the geometry. This notebook is split into the following sections:\n",
    "\n",
    "1. Import required modules\n",
    "2. Read in accuracy data\n",
    "3. Calculate fire severity and fire extent accuracy results (users, producers and overall).\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"./training_accuracy_data.shp\")\n",
    "gdf = gdf.rename(columns={\"Tumbarumba\": \"dNBR\", \"SEVERITY\": \"actual_severity\"})\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__From dNBR raster histogram:__<br>\n",
    "mix value = -0.78936<br>\n",
    "max value = 1.2721"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate each class into separate geodataframes based on the actual (measured) classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_unburnt = gdf.loc[(gdf[\"actual_severity\"] == \"Unburnt\")]\n",
    "actual_low = gdf.loc[(gdf[\"actual_severity\"] == \"Low\")]\n",
    "actual_moderate = gdf.loc[(gdf[\"actual_severity\"] == \"Moderate\")]\n",
    "actual_high = gdf.loc[(gdf[\"actual_severity\"] == \"High\")]\n",
    "actual_extreme = gdf.loc[(gdf[\"actual_severity\"] == \"Extreme\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the classes (less unburnt) on a histogram to find threshold values for separation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(actual_unburnt['dNBR'], bins=30, alpha = 0.5, label='unburnt')\n",
    "plt.hist(actual_low[\"dNBR\"], bins=7, alpha=0.5, label=\"low\")\n",
    "plt.hist(actual_moderate[\"dNBR\"], bins=16, alpha=0.5, label=\"moderate\")\n",
    "plt.hist(actual_high[\"dNBR\"], bins=10, alpha=0.5, label=\"high\")\n",
    "plt.hist(actual_extreme[\"dNBR\"], bins=17, alpha=0.5, label=\"extreme\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.xlabel(\"dNBR\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Fire Severity Class Separability\")\n",
    "\n",
    "plt.savefig(\"class_separability_severity.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extremely poor separability between classes. This could be due to the accuracy data that was sourced by visually intepreting 3m resolution Planet Dove data using false colour cues. It was easy to identify 'extreme' classes that were completed charred and also unburnt healthy areas but distinguishing between low, moderate and high was very difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply threshold values and map the categorical matches to the original geodataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_unburnt = gdf.loc[(gdf[\"dNBR\"] < 0.10)]\n",
    "classified_low = gdf.loc[(gdf[\"dNBR\"] >= 0.10) & (gdf[\"dNBR\"] < 0.30)]\n",
    "classified_moderate = gdf.loc[(gdf[\"dNBR\"] >= 0.30) & (gdf[\"dNBR\"] < 0.50)]\n",
    "classified_high = gdf.loc[(gdf[\"dNBR\"] >= 0.50) & (gdf[\"dNBR\"] < 0.65)]\n",
    "classified_extreme = gdf.loc[(gdf[\"dNBR\"] >= 0.65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_unburnt = classified_unburnt.assign(classified_severity=\"Unburnt\")\n",
    "classified_low = classified_low.assign(classified_severity=\"Low\")\n",
    "classified_moderate = classified_moderate.assign(classified_severity=\"Moderate\")\n",
    "classified_high = classified_high.assign(classified_severity=\"High\")\n",
    "classified_extreme = classified_extreme.assign(classified_severity=\"Extreme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined the results into a new geodataframe and produce a crosstab (accuracy matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [\n",
    "    classified_unburnt,\n",
    "    classified_low,\n",
    "    classified_moderate,\n",
    "    classified_high,\n",
    "    classified_extreme,\n",
    "]\n",
    "results = pd.concat(frames)\n",
    "results = results[[\"dNBR\", \"actual_severity\", \"classified_severity\", \"geometry\"]]\n",
    "results_duplicate = results  # used later on\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab = pd.crosstab(results[\"actual_severity\"], results[\"classified_severity\"])\n",
    "sev = [\"Unburnt\", \"Low\", \"Moderate\", \"High\", \"Extreme\"]\n",
    "\n",
    "xtab = xtab.reindex(sev, axis=\"columns\")\n",
    "xtab = xtab.reindex(sev, axis=\"rows\")\n",
    "xtab.to_csv(\"./dNBR_accuracy_severity_skewed.csv\")\n",
    "xtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracy = (\n",
    "    (\n",
    "        xtab[\"Unburnt\"][\"Unburnt\"]\n",
    "        + xtab[\"Low\"][\"Low\"]\n",
    "        + xtab[\"Moderate\"][\"Moderate\"]\n",
    "        + xtab[\"High\"][\"High\"]\n",
    "        + xtab[\"Extreme\"][\"Extreme\"]\n",
    "    )\n",
    "    / len(gdf)\n",
    "    * 100\n",
    ")\n",
    "\n",
    "overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.groupby(\"actual_severity\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "There is a disproportionally high number of unburnt sample points which have likely skewed the results to be very high. We only need to look at the count to see that unburnt samples make up a majority of the points. Let's see what happens if only 40 points from each class are randomly sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unburnt = results.loc[(gdf[\"actual_severity\"] == \"Unburnt\")]\n",
    "unburnt = unburnt.sample(n=40)\n",
    "\n",
    "low = results.loc[(gdf[\"actual_severity\"] == \"Low\")]\n",
    "low = low.sample(n=40)\n",
    "\n",
    "moderate = results.loc[(gdf[\"actual_severity\"] == \"Moderate\")]\n",
    "moderate = moderate.sample(n=40)\n",
    "\n",
    "high = results.loc[(gdf[\"actual_severity\"] == \"High\")]\n",
    "high = high.sample(n=40)\n",
    "\n",
    "extreme = results.loc[(gdf[\"actual_severity\"] == \"Extreme\")]\n",
    "extreme = extreme.sample(n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [unburnt, low, moderate, high, extreme]\n",
    "results = pd.concat(frames)\n",
    "results = results[[\"dNBR\", \"actual_severity\", \"classified_severity\", \"geometry\"]]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab = pd.crosstab(results[\"actual_severity\"], results[\"classified_severity\"])\n",
    "sev = [\"Unburnt\", \"Low\", \"Moderate\", \"High\", \"Extreme\"]\n",
    "\n",
    "xtab = xtab.reindex(sev, axis=\"columns\")\n",
    "xtab = xtab.reindex(sev, axis=\"rows\")\n",
    "xtab.to_csv(\"./dNBR_accuracy_severity_random.csv\")\n",
    "xtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracy = (\n",
    "    (\n",
    "        xtab[\"Unburnt\"][\"Unburnt\"]\n",
    "        + xtab[\"Low\"][\"Low\"]\n",
    "        + xtab[\"Moderate\"][\"Moderate\"]\n",
    "        + xtab[\"High\"][\"High\"]\n",
    "        + xtab[\"Extreme\"][\"Extreme\"]\n",
    "    )\n",
    "    / len(results)\n",
    "    * 100\n",
    ")\n",
    "\n",
    "overall_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is likely a far more accurate representation of the overall accuracy of this classification. This is still not based considering the very minimal processing overhead for a dNBR compared to a multi-band fully connected neural network approach. Unfortunately, with each different location, scene, weather conditions (pre/post), vegetation ecosystems etc; there is significant variability that the chose threshold values would need to be tweaked to suit each scene. This is where a majority of the time would be spent, and normalising severity from one scene to another become very difficult as moderate in one may not neccessarily map well to moderate in another location with a completely different ecosystem of flora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the accuracy if the only two endmembers were 'Unburnt' or 'Burnt' areas. In order to do this, we re-map low, moderate, high and extreme categorisations in the actual and classified severity columns to 'burnt' and reproduce the crosstab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_duplicate.loc[\n",
    "    results_duplicate.actual_severity == \"Low\", \"actual_severity\"\n",
    "] = \"Burnt\"\n",
    "results_duplicate.loc[\n",
    "    results_duplicate.actual_severity == \"Moderate\", \"actual_severity\"\n",
    "] = \"Burnt\"\n",
    "results_duplicate.loc[\n",
    "    results_duplicate.actual_severity == \"High\", \"actual_severity\"\n",
    "] = \"Burnt\"\n",
    "results_duplicate.loc[\n",
    "    results_duplicate.actual_severity == \"Extreme\", \"actual_severity\"\n",
    "] = \"Burnt\"\n",
    "results_duplicate.loc[\n",
    "    results_duplicate.classified_severity == \"Low\", \"classified_severity\"\n",
    "] = \"Burnt\"\n",
    "results_duplicate.loc[\n",
    "    results_duplicate.classified_severity == \"Moderate\", \"classified_severity\"\n",
    "] = \"Burnt\"\n",
    "results_duplicate.loc[\n",
    "    results_duplicate.classified_severity == \"High\", \"classified_severity\"\n",
    "] = \"Burnt\"\n",
    "results_duplicate.loc[\n",
    "    results_duplicate.classified_severity == \"Extreme\", \"classified_severity\"\n",
    "] = \"Burnt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_duplicate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unburnt = results_duplicate.loc[(results_duplicate[\"actual_severity\"] == \"Unburnt\")]\n",
    "unburnt = unburnt.sample(n=160)\n",
    "\n",
    "burnt = results_duplicate.loc[(results_duplicate[\"actual_severity\"] == \"Burnt\")]\n",
    "burnt = burnt.sample(n=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(unburnt[\"dNBR\"], bins=20, alpha=0.5, label=\"unburnt\")\n",
    "plt.hist(burnt[\"dNBR\"], bins=20, alpha=0.5, label=\"burnt\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.xlabel(\"dNBR\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Fire Extent Class Separability\")\n",
    "\n",
    "plt.savefig(\"class_separability_extent.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [unburnt, burnt]\n",
    "results = pd.concat(frames)\n",
    "results = results[[\"dNBR\", \"actual_severity\", \"classified_severity\", \"geometry\"]]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab = pd.crosstab(results[\"actual_severity\"], results[\"classified_severity\"])\n",
    "sev = [\"Unburnt\", \"Burnt\"]\n",
    "\n",
    "xtab = xtab.reindex(sev, axis=\"columns\")\n",
    "xtab = xtab.reindex(sev, axis=\"rows\")\n",
    "xtab.to_csv(\"./dNBR_accuracy_extent_random.csv\")\n",
    "xtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracy = (\n",
    "    (xtab[\"Unburnt\"][\"Unburnt\"] + xtab[\"Burnt\"][\"Burnt\"]) / len(results) * 100\n",
    ")\n",
    "\n",
    "overall_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the accuracy of the dNBR in identifying between unburnt and burnt areas is approximately 90%. This is very high and a decent result for the identification of burn area extent or boundaries. A good way to really test this however would be to sample many points across known boundary areas in order to determine if the same accuracy still holds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Last modified:** 26 Oct 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sentinel 2`, :index:`NBR`, :index:`time series`, :index:`statistics`, :index:`real world`, :index:`exporting data`, :index:`accuracy assessment`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
