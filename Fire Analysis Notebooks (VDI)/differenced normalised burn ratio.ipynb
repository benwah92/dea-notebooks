{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differenced Normalised Burn Ratio for Tumbarumba, NSW <img align=\"right\" src=\"../DEA reference notebooks/Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `NCI VDI` environment only. Compiled .py script compatible with `NCI Gadi`.\n",
    "* **Products used:** \n",
    "[s2a_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2a_ard_granule), \n",
    "[s2b_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2b_ard_granule)\n",
    "* **Prerequisites:** It is recommended that you statistically and visually inspect the available imagery using the `spectral sampling for statistcal analysis` and `Sentinel-2 plotting` notebooks first to get a better idea of the input variables required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "During the 2020 Black Summer Bushfires, the town of Tumbarumba, NSW was impacted by a fire event that occured on the 05 Jan 2020. By using the analysis ready datasets (Sentinel-2 NBART products) within the DEA Data Cube environments on the NCI, a normalised burn ratio (NBR) for pre and post fire can be calculated in order to create a differnenced normalised burn ratio (dNBR) product. Fire severity and extent can then be inferred from the resulting GeoTIFF that is produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "The DEA Data Cube on the NCI is used to access a temporal stack of imagery approximately two months prior and two months after the fire event. It is recommended that you statistically and visually inspect the available imagery using the `spectral sampling for statistcal analysis` and `Sentinel-2 plotting` notebooks first to get a better idea of the input variables required. This notebook is split into the following steps:\n",
    "\n",
    "1. Import required modules\n",
    "2. Set required spatiotemporal query variables (location, time)\n",
    "3. Chunk scene along the x,y dimensions (in-memory control)\n",
    "4. Calculate dNBR values by iterating spatial chunks\n",
    "5. Mosaic output rasters into one complete dNBR scene\n",
    "6. Output the final result to GeoTIFF.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datacube\n",
    "from datacube.helpers import write_geotiff\n",
    "from datacube.utils import cog\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "\n",
    "sys.path.append(\"/home/554/ab4513/dea-notebooks/Scripts\")\n",
    "import dea_datahandling\n",
    "from dea_bandindices import calculate_indices\n",
    "from dea_datahandling import load_ard\n",
    "from dea_plotting import display_map, rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"dNBR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "* `central_lat`: The centroid latitude in decimal degree of the target area of interest (e.g. `-35.783333`).\n",
    "* `central_lon`: The centroid longitude in decimal degree of the target area of interest (e.g. `148.016667`).\n",
    "* `crs`: The coordinate reference system code for your I/O tasks (e.g. `EPSG:32755`).\n",
    "* `prefire_start`: The pre-fire period start date (e.g. `2019-11-01`).\n",
    "* `prefire_end`: The pre-fire period end date (e.g. `2020-01-06`).\n",
    "* `postfire_start`: The post-fire period start date (e.g. `2020-01-07`).\n",
    "* `postfire_end`: The post-fire period start date (e.g. `2020-05-01`).\n",
    "* `buffer`: The buffer (in arc seconds) around the target coordinates (e.g. `0.2 or 0.4 or 0.6 etc`). Needs to be an even fractional value as per examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the central latitude and longitude\n",
    "central_lat = -35.783333\n",
    "central_lon = 148.016667\n",
    "crs = \"EPSG:32755\"\n",
    "\n",
    "# Key Dates\n",
    "prefire_start = \"2019-11-01\"\n",
    "prefire_end = \"2020-01-06\"\n",
    "postfire_start = \"2020-01-07\"\n",
    "postfire_end = \"2020-05-01\"\n",
    "\n",
    "# Set the buffer to load around the central coordinates (even numbers such as 0.2, 1.0, 2.2 etc) in degrees (lat, lon)\n",
    "buffer = 0.6\n",
    "\n",
    "# Compute the bounding box for the study area\n",
    "study_area_lat = (central_lat - buffer, central_lat + buffer)\n",
    "study_area_lon = (central_lon - buffer, central_lon + buffer)\n",
    "\n",
    "display_map(x=study_area_lon, y=study_area_lat, margin=-0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Memory I/O Control\n",
    "Memory allocations on the NCI VDI is 32GB assuming you are the only user on your particular node. As a query to load data is made, data is read into memory. If the time range or spatial extent is too large, a memory allocation erorr will occur. To avoid this, we will create a list of evenly dispersed coordinates and read in smaller spatial chunks at a time. \n",
    "\n",
    "> **Note:** The script is designed to chunk the analytical area of interest into 0.2° by 0.2° smaller tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range for generating point grid.\n",
    "magic_number = int(buffer * 10 / 1)\n",
    "rng = range(int(magic_number / 2))\n",
    "\n",
    "x_coord = []\n",
    "y_coord = []\n",
    "\n",
    "# Calculate x and y for point grid.\n",
    "for i in rng:\n",
    "    l = i / 5 + 0.1\n",
    "    neg_lat = central_lat - l\n",
    "    neg_lon = central_lon - l\n",
    "    pos_lat = central_lat + l\n",
    "    pos_lon = central_lon + l\n",
    "    x_coord.append(neg_lon)\n",
    "    x_coord.append(pos_lon)\n",
    "    y_coord.append(neg_lat)\n",
    "    y_coord.append(pos_lat)\n",
    "\n",
    "coords = []\n",
    "\n",
    "# Create list of shapely points.\n",
    "for x in x_coord:\n",
    "    for y in y_coord:\n",
    "        p = Point(x, y)\n",
    "        coords.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Execute dNBR Calculation\n",
    "Next we define a function that will interatively query for Sentinel-2 NBART imagery, calculate a dNBR tile and write the output to a local GeoTIFF file store in a subfolder. Once defined, we iterate through all the coordinates to compute all the dNBR tiles.\n",
    "\n",
    "> **Note:** Using the default notebook parameters on the NCI VDI, this will take approximately 30mins. The NCI VDI allocates users with a 2GB local storage allocation. If you exceed this limit, try reducing your spatial extent or temporal range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dNBR_processing(coordinates):\n",
    "\n",
    "    # Load all data in baseline period available from s2a/b_ard_granule datasets\n",
    "    prefire_ard = load_ard(\n",
    "        dc=dc,\n",
    "        products=[\"s2a_ard_granule\", \"s2b_ard_granule\"],\n",
    "        x=(coordinates.x - 0.1, coordinates.x + 0.1),\n",
    "        y=(coordinates.y - 0.1, coordinates.y + 0.1),\n",
    "        time=(prefire_start, prefire_end),\n",
    "        measurements=[\"nbart_nir_1\", \"nbart_swir_3\"],\n",
    "        min_gooddata=0.1,\n",
    "        output_crs=\"EPSG:32755\",  # UTM Zone 55S\n",
    "        resolution=(-10, 10),\n",
    "        group_by=\"solar_day\",\n",
    "    )\n",
    "\n",
    "    prefire_ard = calculate_indices(\n",
    "        prefire_ard, index=\"NBR\", collection=\"ga_s2_1\", drop=False\n",
    "    )\n",
    "\n",
    "    # Compute median using all observations in the dataset along the time axis\n",
    "    prefire_image = prefire_ard.median(dim=\"time\")\n",
    "\n",
    "    # Delete baseline_combined\n",
    "    del prefire_ard\n",
    "\n",
    "    # Select NBR\n",
    "    prefire_NBR = prefire_image.NBR\n",
    "\n",
    "    del prefire_image\n",
    "\n",
    "    # Load all data in post-fire period available from s2a/b_ard_granule datasets\n",
    "    postfire_ard = load_ard(\n",
    "        dc=dc,\n",
    "        products=[\"s2a_ard_granule\", \"s2b_ard_granule\"],\n",
    "        x=(coordinates.x - 0.1, coordinates.x + 0.1),\n",
    "        y=(coordinates.y - 0.1, coordinates.y + 0.1),\n",
    "        time=(postfire_start, postfire_end),\n",
    "        measurements=[\"nbart_nir_1\", \"nbart_swir_3\"],\n",
    "        min_gooddata=0.1,\n",
    "        output_crs=\"EPSG:32755\",  # UTM Zone 55S\n",
    "        resolution=(-10, 10),\n",
    "        group_by=\"solar_day\",\n",
    "    )\n",
    "\n",
    "    # Calculate NBR on all post-fire images\n",
    "    postfire_ard = calculate_indices(\n",
    "        postfire_ard, index=\"NBR\", collection=\"ga_s2_1\", drop=False\n",
    "    )\n",
    "\n",
    "    # Calculate the median post-fire image\n",
    "    postfire_image = postfire_ard.median(dim=\"time\")\n",
    "\n",
    "    del postfire_ard\n",
    "\n",
    "    # Select NBR\n",
    "    postfire_NBR = postfire_image.NBR\n",
    "\n",
    "    del postfire_image\n",
    "\n",
    "    # Calculate delta\n",
    "    delta_NBR = prefire_NBR - postfire_NBR\n",
    "\n",
    "    del prefire_NBR\n",
    "    del postfire_NBR\n",
    "\n",
    "    x = np.round_(coordinates.x, decimals=4)\n",
    "    y = np.round_(coordinates.y, decimals=4)\n",
    "\n",
    "    # Turn dNBR into a x-array dataset for export to GeoTIFF\n",
    "    dnbr_dataset = delta_NBR.to_dataset(name=\"delta_NBR\")\n",
    "    # cog.write_cog(dnbr_dataset, './NBR_geotiffs/{x}_{y}_dNBR.tif')\n",
    "    write_geotiff(f\"./dNBR_geotiffs/{x}_{y}_dNBR.tif\", dnbr_dataset)\n",
    "\n",
    "    del delta_NBR\n",
    "    del dnbr_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Iterate through all shapely points to generate a dNBR geotiff.\n",
    "for i in coords:\n",
    "    dNBR_processing(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mosaic GeoTIFF tiles into one GeoTIFF dNBR Product\n",
    "Lastly, we read into all the dNBR tiles that were created and using the Rasterio module, mosaic the tiles into a larger GeoTIFF and save the final product as a GeoTIFF. The dirpath and out_fp locals will need to be changes to your specific files locations. Once complete, you can using SSH to download the final dNBR product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = r\"/home/554/ab4513/dea-notebooks/My Notebooks/dNBR_geotiffs\"\n",
    "out_fp = (\n",
    "    r\"/home/554/ab4513/dea-notebooks/My Notebooks/dNBR_geotiffs/Tumbarumba_dNBR.tif\"\n",
    ")\n",
    "\n",
    "# Make a search criteria to select the DEM files\n",
    "search_criteria = \"1*.tif\"\n",
    "q = os.path.join(dirpath, search_criteria)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_fps = glob.glob(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_files_to_mosaic = []\n",
    "for fp in dem_fps:\n",
    "    src = rasterio.open(fp)\n",
    "    src_files_to_mosaic.append(src)\n",
    "\n",
    "src_files_to_mosaic\n",
    "\n",
    "mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "show(mosaic, cmap=\"plasma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_meta = src.meta.copy()\n",
    "out_meta.update(\n",
    "    {\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": mosaic.shape[1],\n",
    "        \"width\": mosaic.shape[2],\n",
    "        \"transform\": out_trans,\n",
    "        \"crs\": crs,\n",
    "    }\n",
    ")\n",
    "\n",
    "with rasterio.open(out_fp, \"w\", **out_meta) as dest:\n",
    "    dest.write(mosaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "Contains modified Copernicus data (2020) processed by Digital Earth Australia.\n",
    "\n",
    "**Last modified:** 26 Oct 2020.\n",
    "\n",
    "**Compatible datacube version:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sentinel 2`, :index:`NBR`, :index:`time series`, :index:`GeoTIFF`, :index:`real world`, :index:`exporting data`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
